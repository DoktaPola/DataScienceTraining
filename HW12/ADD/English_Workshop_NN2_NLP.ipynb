{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English_Workshop_NN2_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzjYwQHfl6Ih"
      },
      "source": [
        "# !wget -O quora.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ERtxpdWOgGQ3HOigqAMHTJjmOE_tWvoF\"\n",
        "# !unzip quora.zip\n",
        "# !pip install -q --upgrade nltk gensim bokeh pandas\n",
        "\n",
        "# import numpy as np\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "# np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqAnq1aPi-mo",
        "outputId": "605524cc-2ef4-4be7-9642-ac9142543c44"
      },
      "source": [
        "!pip install -qq nltk==3.4\n",
        "!pip install -qq gensim==3.6.0\n",
        "!pip install -qq pandas==0.23.4\n",
        "!pip install -qq bokeh==1.0.3\n",
        "\n",
        "!wget -O quora.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ERtxpdWOgGQ3HOigqAMHTJjmOE_tWvoF\"\n",
        "!unzip quora.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: xarray 0.18.2 has requirement pandas>=1.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pymc3 3.11.2 has requirement pandas>=0.24.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: panel 0.11.3 has requirement bokeh<2.4.0,>=2.3.0, but you'll have bokeh 1.0.3 which is incompatible.\u001b[0m\n",
            "Archive:  quora.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ob6cY-EjMWQ",
        "outputId": "404520f0-698b-4d8c-a8ad-d5dbd905d6b8"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl16AOdtlDk"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErZ_TOu0vAOR"
      },
      "source": [
        "*NB. This notebook is somewhat based on the YSDA NLP course [notebook](https://github.com/yandexdataschool/nlp_course/tree/master/week01_embeddings).*\n",
        "\n",
        "Guess, you've seen such pictures already:  \n",
        "![embeddings relations](https://www.tensorflow.org/images/linear-relationships.png)\n",
        "*From [Vector Representations of Words, Tensorflow tutorial](https://www.tensorflow.org/tutorials/representation/word2vec)*\n",
        "\n",
        "We are going to use these thingies alo-o-ot.\n",
        "\n",
        "Well, we need a proper introduction, nevertheless. Simple baseline.\n",
        "\n",
        "We can convert a sentence to the bag-of-words:  \n",
        "![](https://i.ibb.co/Tvw1c8S/BOW.png)\n",
        "\n",
        "And each word was represented using one-hot encoding (a vector with one at the position corresponding to the word's index and zeros at all others positions).\n",
        "\n",
        "These one-hot encoding vectors have extremely high dimensions (like, hundreds of thousands or millions). They fit their purpose - to encode information about words. But they have several disadvantages.\n",
        "\n",
        "First of all, they are almost uninterpretable. I mean, all one-hot encoding vectors are orthonormal, so you cannot say that, e.g. `man` and `men` are more similar words than `man` and `crocodiles`.\n",
        "\n",
        "But we want to. Well, NLP researchers in the past few years wanted to, cannot really speak for you.\n",
        "\n",
        "And we're gonna build vectors, that encode semantics!\n",
        "\n",
        "Look at the first picture. It shows relations encoded in the word embeddings space. Such as male-female or verb tense... whatever, just check these two links: http://bionlp-www.utu.fi/wv_demo/, https://lamyiowce.github.io/word2viz/. Go and play with this relations right now! They are funny and you'll get an insight into what the word embeddings can.\n",
        "\n",
        "There is another disadvantage of one-hot encoding vectors: their size. The word embedding vectors we are going to play with have dimensions from 50 to 600 usually. That is by a few orders of magnitude smaller than one-hot encoding vectors.\n",
        "\n",
        "This is crucial for neural networks - they can work only with sufficiently small dense vectors. Well, we'll speak about it later.\n",
        "\n",
        "---\n",
        "\n",
        "In this notebook, we are going to work with [gensim](https://radimrehurek.com/gensim/) - somewhat standard word embeddings python library. We'll just superficially discuss how it works, but we'll train our model and apply a pretrained one. As a result, you're (probably) gonna understand how to work with word embeddings.\n",
        "\n",
        "In the next notebook, we'll try to work out how word embeddings work and how to implement a module to train word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkxsGQqZNjxj"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaOn69Bg1hH-"
      },
      "source": [
        "Well, nothing is interesting in mere training of the word embeddings model. We are gonna apply it to a very concrete task: [Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs) from kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1N9peq_jx40"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "quora_data = pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er7YDUuVOl7F"
      },
      "source": [
        "quora_data.sample(20)[['question1', 'question2', 'is_duplicate']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "ybl95489HDwA",
        "outputId": "cbc02ce0-00b8-42bf-c8c5-0cea0bcb7cfd"
      },
      "source": [
        "!pip install --upgrade pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Using cached https://files.pythonhosted.org/packages/51/51/48f3fc47c4e2144da2806dfb6629c4dd1fa3d5a143f9652b141e979a8ca9/pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.23.4\n",
            "    Uninstalling pandas-0.23.4:\n",
            "      Successfully uninstalled pandas-0.23.4\n",
            "Successfully installed pandas-1.2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "2kJb3ZuJG90s",
        "outputId": "41dccb1a-d46f-4a07-d43d-b76f9fbb95fc"
      },
      "source": [
        "quora_data.sample(20)[['question1', 'question2', 'is_duplicate']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210894</th>\n",
              "      <td>Which app can I use to lock gallery and messeg...</td>\n",
              "      <td>Which app can I use to lock gallery and messag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212825</th>\n",
              "      <td>What are some movie remakes that surpass the o...</td>\n",
              "      <td>What movie sequels are better than the originals?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191995</th>\n",
              "      <td>How is the life of an American teenager?</td>\n",
              "      <td>How is the life of american teenagers when com...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25948</th>\n",
              "      <td>What is most important for starting a new busi...</td>\n",
              "      <td>What are the five most important consideration...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199166</th>\n",
              "      <td>How can I cure weak eyesight?</td>\n",
              "      <td>How do I test if my eyesight is weak?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164928</th>\n",
              "      <td>What would you do if you fall in love with you...</td>\n",
              "      <td>What would you do if you fell in love with you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6403</th>\n",
              "      <td>Why do people in many developing countries thi...</td>\n",
              "      <td>Is China a developed country?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179850</th>\n",
              "      <td>Where can we find details of a journal?</td>\n",
              "      <td>Where can I find article templates that follow...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103735</th>\n",
              "      <td>What is the relationship between commutator an...</td>\n",
              "      <td>What is the difference between slip ring and c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259105</th>\n",
              "      <td>Why is it a good thing when you break a sweat ...</td>\n",
              "      <td>Why does fever increase during night time?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267359</th>\n",
              "      <td>What would happen if Ukraine joins NATO?</td>\n",
              "      <td>What would happen if NATO incorporated Ukraine...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77326</th>\n",
              "      <td>Is it a good idea to buy a used car from a ren...</td>\n",
              "      <td>Is it a good idea to buy a used car from a car...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237276</th>\n",
              "      <td>I m planning for sunburn Pune 2016. Is anyone ...</td>\n",
              "      <td>If I wrote in Ted Cruz on my ballot in Novembe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>Is the US election rigged?</td>\n",
              "      <td>Was the US election rigged?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361572</th>\n",
              "      <td>How many views and answers are required to bec...</td>\n",
              "      <td>How does someone become a top writer in Quora ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200509</th>\n",
              "      <td>How do I build passive income streams?</td>\n",
              "      <td>What are some ways to create passive income st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168150</th>\n",
              "      <td>What does the Black Lives Matter movement seek...</td>\n",
              "      <td>What is actual agenda of Black Lives Matter?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56433</th>\n",
              "      <td>Which is the best RO water purifier in Patna?</td>\n",
              "      <td>Which is the best ro water purifier in chennai?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194223</th>\n",
              "      <td>How can I get more subscribers/views on my You...</td>\n",
              "      <td>How can I advertise my YouTube Channel to get ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310381</th>\n",
              "      <td>What is the right time to visit kerala back wa...</td>\n",
              "      <td>What is the best time to visit Kerala, India?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question1  ... is_duplicate\n",
              "210894  Which app can I use to lock gallery and messeg...  ...            1\n",
              "212825  What are some movie remakes that surpass the o...  ...            0\n",
              "191995           How is the life of an American teenager?  ...            1\n",
              "25948   What is most important for starting a new busi...  ...            1\n",
              "199166                      How can I cure weak eyesight?  ...            0\n",
              "164928  What would you do if you fall in love with you...  ...            1\n",
              "6403    Why do people in many developing countries thi...  ...            0\n",
              "179850            Where can we find details of a journal?  ...            0\n",
              "103735  What is the relationship between commutator an...  ...            1\n",
              "259105  Why is it a good thing when you break a sweat ...  ...            0\n",
              "267359           What would happen if Ukraine joins NATO?  ...            1\n",
              "77326   Is it a good idea to buy a used car from a ren...  ...            1\n",
              "237276  I m planning for sunburn Pune 2016. Is anyone ...  ...            0\n",
              "665                            Is the US election rigged?  ...            1\n",
              "361572  How many views and answers are required to bec...  ...            1\n",
              "200509             How do I build passive income streams?  ...            1\n",
              "168150  What does the Black Lives Matter movement seek...  ...            1\n",
              "56433       Which is the best RO water purifier in Patna?  ...            0\n",
              "194223  How can I get more subscribers/views on my You...  ...            1\n",
              "310381  What is the right time to visit kerala back wa...  ...            0\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p13HdkzWKtKe"
      },
      "source": [
        "You see, the dataset consists of question pairs and you have to determine which of them are duplicates and which are not.\n",
        "\n",
        "Well, I'm not promising that we'll achieve good results right now, but still... Let's train Word2vec gensim model!\n",
        "\n",
        "*Word2vec is the most popular method of building word embeddings. We'll implement it next time, right now let's believe that it just do whatever we want.*\n",
        "\n",
        "First of all, we need to collect available texts to pass them to Word2vec model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mchv4fS_21OX"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "quora_data.question1 = quora_data.question1.replace(np.nan, '', regex=True)\n",
        "quora_data.question2 = quora_data.question2.replace(np.nan, '', regex=True)\n",
        "\n",
        "texts = list(pd.concat([quora_data.question1, quora_data.question2]).unique())\n",
        "texts[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hZMFAmvK5b7"
      },
      "source": [
        "Next, we have to tokenize the texts. This time we'll use `nltk` - another great NLP library. \n",
        "\n",
        "It goes this way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTxolf8nLM-n"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize(texts[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuJceE4JLRxK"
      },
      "source": [
        "**Task** Your turn: lowercase all the texts and tokenize them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7XbnSdt4REg"
      },
      "source": [
        "tokenized_texts = [<do it>]\n",
        "\n",
        "assert all(isinstance(row, (list, tuple)) for row in tokenized_texts), \\\n",
        "    \"please convert each line into a list of tokens\"\n",
        "assert all(all(isinstance(tok, str) for tok in row) for row in tokenized_texts), \\\n",
        "    \"please convert each line into a list of tokens\"\n",
        "\n",
        "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
        "assert all(not is_latin(token) or token.islower() for tokens in tokenized_texts for token in tokens),\\\n",
        "    \"please lowercase each line\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irl7RotC5C_B"
      },
      "source": [
        "print([' '.join(row) for row in tokenized_texts[:2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kj4dC3iLdwH"
      },
      "source": [
        "And we are ready to train a small model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GNuiLio8M25"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(tokenized_texts, \n",
        "                 size=32,      # embedding vector size\n",
        "                 min_count=5,  # consider words that occured at least 5 times\n",
        "                 window=5,     # define context as a 5-word window around the target word\n",
        "                 seed=0,       # + workers=1 is to make model reproducible\n",
        "                 workers=1).wv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JclToDJMNwTy"
      },
      "source": [
        "## Analyzing Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBVR2kY7LkCs"
      },
      "source": [
        "Yay, we have our own model, let's play with it!\n",
        "\n",
        "To get word's vector, well, call `get_vector`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk6Fgraj-j3c"
      },
      "source": [
        "model.get_vector('anything')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHKRy7HyLuxH"
      },
      "source": [
        "To get most similar words for the given one (guess, what):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toyNzyTB-p70"
      },
      "source": [
        "model.most_similar('bread')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A510z5gTL00E"
      },
      "source": [
        "And it can do such magic:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2A_DF5E-ucq"
      },
      "source": [
        "model.most_similar(positive=['coder', 'money'], negative=['brain'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-_uKG4vNIJv"
      },
      "source": [
        "That is, who is like coder, with money and without brains.\n",
        "\n",
        "And this too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_mzQgi4L474"
      },
      "source": [
        "model.most_similar([model.get_vector('politician') - model.get_vector('power') + model.get_vector('honesty')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5BAEyMyL2kx"
      },
      "source": [
        "Honest politician without power, isn't it just cute.\n",
        "\n",
        "**Task** Play with it. And yes, I'm serious."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F_3hQxqn16s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FYuh4DKN1Fd"
      },
      "source": [
        "## Visualizing Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdT0eIEiN4Ja"
      },
      "source": [
        "Let's now look at the projection of the first 1000 the most frequent words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1e9yS0zBr6j"
      },
      "source": [
        "words = sorted(model.vocab.keys(), \n",
        "               key=lambda word: model.vocab[word].count,\n",
        "               reverse=True)[:1000]\n",
        "\n",
        "print(words[::100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yk5pgMXOESS"
      },
      "source": [
        "**Task** Build the matrix from these words' vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQu724f2CAh0"
      },
      "source": [
        "word_vectors = model.vectors[[model.vocab[word].index for word in words]]\n",
        "\n",
        "assert isinstance(word_vectors, np.ndarray)\n",
        "assert word_vectors.shape == (len(words), model.vectors.shape[1])\n",
        "assert np.isfinite(word_vectors).all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA3onWUbcWAo"
      },
      "source": [
        "Now we would try to project this 32 dimensional vectors to the more convenient 2D space to be able to look on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7cgxin-OTvK"
      },
      "source": [
        "### PCA\n",
        "\n",
        "The simplest linear method of dimension reduction is __P__rincipial __C__omponent __A__nalysis.\n",
        "\n",
        "PCA builds so called principal components - set of variables along which our data has the largest variance:  \n",
        "\n",
        "![pca](https://i.stack.imgur.com/Q7HIP.gif)\n",
        "*From the great answer [https://stats.stackexchange.com/a/140579](https://stats.stackexchange.com/a/140579)*\n",
        "\n",
        "For instance, in the picture, the rotating line represents possible variants of the first principal component. If we want to project 2D set of dots to one dimension, we'll probably want to save as much information as possible. The maximum variance position of the rotating line gives us more information about the dots than all other positions.\n",
        "\n",
        "Really nice illustrations of this mechanism live [here](http://setosa.io/ev/principal-component-analysis/).\n",
        "\n",
        "To be short, project multi-dimensional space on the first two or three components and enjoy fast-and-dirty dimensional reduction.\n",
        "\n",
        "**Task** Use [sklearn PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to project data to 2D. Centre and normalize the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0fQKZw2Css4"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def get_pca_projection(word_vectors):\n",
        "    <implement me>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_9VtLl9CviW"
      },
      "source": [
        "word_vectors_pca = get_pca_projection(word_vectors)\n",
        "\n",
        "assert word_vectors_pca.shape == (len(word_vectors), 2), \"there must be a 2d vector for each word\"\n",
        "assert max(abs(word_vectors_pca.mean(0))) < 1e-5, \"points must be zero-centered\"\n",
        "assert max(abs(1 - word_vectors_pca.std(0))) < 1e-5, \"points must have unit variance\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGyvhrk7Rlyt"
      },
      "source": [
        "Let's visualize the embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U58YxF3Cx0W"
      },
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBljy2hCC1qX"
      },
      "source": [
        "draw_vectors(word_vectors_pca[:, 0], word_vectors_pca[:, 1], token=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOIU8uXnSItf"
      },
      "source": [
        "### T-SNE\n",
        "\n",
        "There is a more complicated method of data visualization. It's called t-SNE. You can gain an intuition behind it from [this](https://distill.pub/2016/misread-tsne/) article (warning: even more beautiful illustrations).\n",
        "\n",
        "**Task** Well, the same as the previous one: apply [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html), normalize and center the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-nlN4_aDF9G"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def get_tsne_projection(word_vectors):\n",
        "    <fill me>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_YFR_rYDK2n"
      },
      "source": [
        "word_tsne = get_tsne_projection(word_vectors)\n",
        "draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz6uHYMbSjuE"
      },
      "source": [
        "## Using Pretrained Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4GEypE4SokX"
      },
      "source": [
        "We can also use a pretrained embeddings model. There are a number of such models in gensim, you can call `api.info()` to get the list.\n",
        "\n",
        "Let's load a model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUDRtumXXF3S"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load('glove-twitter-100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6CST4OCyCBF"
      },
      "source": [
        "## Building Phrase Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eypMhlOSXFWN"
      },
      "source": [
        "The simplest way to obtain a phrase embedding is to average embeddings of the words in the phrase.\n",
        "\n",
        "*You are probably thinking, 'What a dumb idea, why on earth the average of embedding should contain any useful information'. Well, check [this paper](https://arxiv.org/pdf/1805.09843.pdf).*\n",
        "\n",
        "Let's do it: tokenize and lowercase the texts, calc the mean embedding for the words with known embeddings.\n",
        "\n",
        "**Task** Implement the following function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F76HGRGDEPVq"
      },
      "source": [
        "def get_phrase_embedding(model, phrase):\n",
        "    \"\"\" Calcs phrase embedding as a mean of known word embeddings in the phrase. \n",
        "    If all the words are unknown, returns zero vector.\n",
        "    :param model: KeyedVectors instance\n",
        "    :param phrase: str or list of str (tokenized text)\n",
        "    \"\"\"    \n",
        "    embedding = np.zeros([model.vector_size], dtype='float32')\n",
        "    \n",
        "    if isinstance(phrase, str):\n",
        "        words = word_tokenize(phrase.lower())\n",
        "    else:\n",
        "        words = phrase\n",
        "    \n",
        "    <implement me>\n",
        "    \n",
        "    return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i12XsqnIXfko"
      },
      "source": [
        "vector = get_phrase_embedding(model, \"I'm very sure. This never happened to me before...\")\n",
        "\n",
        "assert np.allclose(vector[::10],\n",
        "                   np.array([ 0.30757686, -0.05861897,  0.143751  , -0.11104885, -0.96929336,\n",
        "                             -0.21928601,  0.21652265,  0.14978765,  1.4842536 ,  0.017826  ],\n",
        "                              dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl2nBZG0WAUx"
      },
      "source": [
        "Well, we are ready to embed all the sentences in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40LezFEJFwv3"
      },
      "source": [
        "text_vectors = np.array([get_phrase_embedding(model, phrase) for phrase in tokenized_texts])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBj8XMZvWFTv"
      },
      "source": [
        "What can we do with it? Now we are able perform search of the nearest neighbours to the given phrase in our base!\n",
        "\n",
        "How are we going to define the distance?\n",
        "\n",
        "We'll use cosine similarity of two vectors:\n",
        "$$\\text{cosine_similarity}(x, y) = \\frac{x^{T} y}{||x||\\cdot ||y||}$$\n",
        "\n",
        "*It's not a [distance](https://www.encyclopediaofmath.org/index.php/Metric) strictly speaking but we still can use it to search for the vectors.*\n",
        "\n",
        "**Task** Calc the similarity between `query` embedding and `text_vectors` using `cosine_similarity` function. Find `k` vectors with highest scores and return corresponding texts from `texts` list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjw7kTQ-FP11"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def find_nearest(model, text_vectors, texts, query, k=10):\n",
        "    <implement me too>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2yK0twNGWaQ"
      },
      "source": [
        "results = find_nearest(model, text_vectors, texts, query=\"How do i enter the matrix?\", k=10)\n",
        "\n",
        "print('\\n'.join(results))\n",
        "\n",
        "assert len(results) == 10 and isinstance(results[0], str)\n",
        "assert results[1] == 'How do I get to the dark web?'\n",
        "assert results[4] == 'What can I do to save the world?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AutTfxbDGhku"
      },
      "source": [
        "find_nearest(model, text_vectors, texts, query=\"How does Trump?\", k=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Ff7heKGiGV"
      },
      "source": [
        "find_nearest(model, text_vectors, texts, query=\"Why don't i ask a question myself?\", k=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BhDEF11ZnTY"
      },
      "source": [
        "## Starting Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D_LEV8cm0z3"
      },
      "source": [
        "### Bag-of-Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xlZZKWOE2ME"
      },
      "source": [
        "Finally, we are ready to return to the classification task.\n",
        "\n",
        "We have two sentences and we are going calculate their similarity and compare it with some threshold. If the value is higher than the threshold then we'll call the sentences similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGge73gDid99"
      },
      "source": [
        "Let's start with tokenization of the questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJTjqdgiih7O"
      },
      "source": [
        "tokenized_question1 = [word_tokenize(question.lower()) for question in quora_data.question1]\n",
        "tokenized_question2 = [word_tokenize(question.lower()) for question in quora_data.question2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT0GPAFnJv-8"
      },
      "source": [
        "assert tokenized_question1[0] == ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india', '?']\n",
        "assert tokenized_question2[2] == ['how', 'can', 'internet', 'speed', 'be', 'increased', 'by', 'hacking', 'through', 'dns', '?']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VBcipE7Ztkc"
      },
      "source": [
        "**Task** Calc the cosine similarity between the questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItJLR_ENHGtI"
      },
      "source": [
        "question1_vectors = <calc vectors for tokenized_question1>\n",
        "question2_vectors = <calc vectors for tokenized_question2>\n",
        "\n",
        "cosine_similarities = <calc similarities between the vectors in question1_vectors and question2_vectors>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5rdNs01vgoI"
      },
      "source": [
        "assert cosine_similarities.shape == (len(quora_data),), 'Check the shapes'\n",
        "\n",
        "target_similarity = cosine_similarity([get_phrase_embedding(model, tokenized_question1[1])], \n",
        "                                      [get_phrase_embedding(model, tokenized_question2[1])])[0, 0]\n",
        "assert np.allclose(cosine_similarities[1], target_similarity), 'Check your calculations'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgCVueJ4Z3DQ"
      },
      "source": [
        "Let's find the texts' similarity threshold.\n",
        "\n",
        "We are going to optimize accuracy of the similarity prediction. For instance, accuracy with threshold equal to 0 would be equal to the fraction ones in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEzgi-o5OieT"
      },
      "source": [
        "(quora_data.is_duplicate == 1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJvse7gpO4-E"
      },
      "source": [
        "**Task** Implement the `accuracy` function that calculates accuracy with the given threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41hRIb-KSA3F"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def accuracy(cosine_similarities, threshold, labels):\n",
        "    return <implement me>\n",
        "\n",
        "thresholds = np.linspace(0, 1, 100, endpoint=False)\n",
        "plt.plot(thresholds, [accuracy(cosine_similarities, th, quora_data.is_duplicate) for th in thresholds])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOxJSE38msmX"
      },
      "source": [
        "Let's optimize over this function to find the optimal threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3LVCJwqSgZz"
      },
      "source": [
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "res = minimize_scalar(\n",
        "    lambda th: -accuracy(cosine_similarities, th, quora_data.is_duplicate), bounds=(0.5, 0.99), method='bounded'\n",
        ")\n",
        "\n",
        "best_threshold = res.x\n",
        "best_accuracy = accuracy(cosine_similarities, best_threshold, quora_data.is_duplicate)\n",
        "print('Threshold = {:.5f}, Accuracy = {:.2%}'.format(best_threshold, best_accuracy))\n",
        "\n",
        "assert best_accuracy > 0.65, 'Check yourself'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R31CunmePSLY"
      },
      "source": [
        "Well, we are a bit better than random :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8yFlaffm34A"
      },
      "source": [
        "### Tf-idf Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cpeSa-4m64H"
      },
      "source": [
        "The averaging of vectors is boring. We can use weighted average - with tf-idf weights.\n",
        "\n",
        "Let's use `TfidfVectorizer` for this task.\n",
        "\n",
        "You see, `TfidfVectorizer` returns matrix `(samples_count, words_count)`. Our embeddings is a matrix `(words_count, embedding_dim)`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjwLoOHx7ChZ"
      },
      "source": [
        "model.vectors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VaVrx3j7I9l"
      },
      "source": [
        "The embedding of a sequence of words $w_1, \\ldots, w_k$, as we defined, it is vector $\\sum_i \\text{idf}(w_i) \\cdot \\text{embedding}(w_i)$.\n",
        "\n",
        "That means that we can multiply matrices `(samples_count, words_count) x (words_count, embedding_dim)` to obtain the embeddings for all phrases we have.\n",
        "\n",
        "But we need to have corresponding words in both matrices. That is i-th row in the first matrix correspond to the i-th column in the second matrix.\n",
        "\n",
        "To achieve it, we are going to use `vocabulary` argument of `TfidfVectorizer`.\n",
        "\n",
        "We can extract the vocabulary this way from the gensim model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCFfdtf25ukF"
      },
      "source": [
        "vocabulary = {word: vocab_element.index for word, vocab_element in model.vocab.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDo4xkQl9mND"
      },
      "source": [
        "Initialize the vectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_tM8LMk5jgc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
        "\n",
        "vectorizer.fit(texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uu5gILFElhx"
      },
      "source": [
        "**Task** Apply `vectorizer` to the `quora_data` questions and obtain the phrase vectors by multiplying them on `model.vectors`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoYjVExHd_OC"
      },
      "source": [
        "tfidf_question1 = <calc it>\n",
        "tfidf_question2 = <and it>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGM1HvnwwwYj"
      },
      "source": [
        "assert tfidf_question1.shape == tfidf_question2.shape == (len(quora_data), len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34Di8jXxoBxg"
      },
      "source": [
        "Check, that the text in matrices is correctly encoded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k52NtVJKf1Wl"
      },
      "source": [
        "for col in tfidf_question1[0].tocoo().col:\n",
        "    print(model.index2word[col], end=' ')\n",
        "\n",
        "print('\\n' + ' '.join(tokenized_question1[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNBcFog40fa8"
      },
      "source": [
        "Now we are able to convert the vectors matrices to vectors. That is, multiply tfidf and word2vec matrices and nomalize the result by the number of words in each sentence.\n",
        "\n",
        "**Task** Build the question vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWGN_z0UxBNL"
      },
      "source": [
        "EPS = 1e-9\n",
        "\n",
        "question1_elements_count = <calc it, add EPS to ensure you don't divide by zero>\n",
        "question2_elements_count = <and it too>\n",
        "\n",
        "assert question1_elements_count.shape == question2_elements_count.shape == (len(quora_data), 1)\n",
        "assert np.all(question1_elements_count > 0) and np.all(question2_elements_count > 0.)\n",
        "\n",
        "question1_vectors = <calc mean tfidf-weighted vectors>\n",
        "question2_vectors = <and these too>\n",
        "\n",
        "assert question1_vectors.shape == question2_vectors.shape == (len(quora_data), model.vectors.shape[1])\n",
        "\n",
        "assert np.allclose(question1_vectors[0][:10], [ 0.04672134, -0.00910798,  0.06817335,  0.00792347,  0.00907249,\n",
        "                                                0.05163505,  0.02648487, -0.05109346,  0.04752091, -0.01203835])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fMqY5tOoL9r"
      },
      "source": [
        "**Task** Evaluate the quality of these embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP46USWDy2Ah"
      },
      "source": [
        "cosine_similarities = <calc them>\n",
        "assert cosine_similarities.shape == (len(quora_data),), 'Check the shapes'\n",
        "assert np.allclose(cosine_similarities[:5], [0.99604267, 0.9558047 , 0.973884  , 0.79243606, 0.92760015])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chf2qy7uhbPF"
      },
      "source": [
        "res = minimize_scalar(\n",
        "    lambda th: -accuracy(cosine_similarities, th, quora_data.is_duplicate), bounds=(0.5, 0.99), method='bounded'\n",
        ")\n",
        "\n",
        "best_threshold = res.x\n",
        "best_accuracy = accuracy(cosine_similarities, best_threshold, quora_data.is_duplicate)\n",
        "print('Threshold = {:.5f}, Accuracy = {:.2%}'.format(best_threshold, best_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvqrFUS6vVhh"
      },
      "source": [
        "## Implementing Word-level Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CXcr-ypzGXg"
      },
      "source": [
        "!wget -O ukr_rus.train.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1vAK0SWXUqei4zTimMvIhH3ufGPsbnC_O\"\n",
        "!wget -O ukr_rus.test.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1W9R2F8OeKHXruo2sicZ6FgBJUTJc8Us_\"\n",
        "!wget -O fairy_tale.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1sq8zSroFeg_afw-60OmY8RATdu_T1tej\"\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1d7OXuil646jUeDS1JNhP9XWlZogv6rbu'})\n",
        "downloaded.GetContentFile('cc.ru.300.vec.zip')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1yAqwqgUHtMSfGS99WLGe5unSCyIXfIxi'})\n",
        "downloaded.GetContentFile('cc.uk.300.vec.zip')\n",
        "\n",
        "!unzip cc.ru.300.vec.zip\n",
        "!unzip cc.uk.300.vec.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RqUeOXxws8y"
      },
      "source": [
        "Let's implement a simple machine translator.\n",
        "\n",
        "The idea is based on the paper [Word Translation Without Parallel Data](https://arxiv.org/pdf/1710.04087.pdf). There are lots of interesting things in the repo: [https://github.com/facebookresearch/MUSE](https://github.com/facebookresearch/MUSE).\n",
        "\n",
        "And we are going to translate from Ukrainian to Russian. They are quite similar languages with similar syntax. This is why we can substitute words from one language with words from another and expect something coherent in the result.\n",
        "\n",
        "That is, we are going to learn how embeddings from one language correspond to embeddings from another, like this:\n",
        "\n",
        "![](https://raw.githubusercontent.com/facebookresearch/MUSE/master/outline_all.png)\n",
        "\n",
        "Than we will simply map the source word (the word in the sentence we want to translate) to the target embedding space and take the word with the nearest embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjPj9FTRry0U"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")\n",
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGx4TXWFJ65"
      },
      "source": [
        "Look at the pair `-` (which are translation, means august)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkHer36xyh4n"
      },
      "source": [
        "ru_emb.most_similar([ru_emb[\"\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RSDixWvylEP"
      },
      "source": [
        "uk_emb.most_similar([uk_emb[\"\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwmm3YQ1yl1U"
      },
      "source": [
        "ru_emb.most_similar([uk_emb[\"\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAsW7oxszE_I"
      },
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\", encoding='utf8') as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)\n",
        "\n",
        "\n",
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")\n",
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z6ts7DC0XmN"
      },
      "source": [
        "### Learning the mapping from the embedding spaces\n",
        "\n",
        "We have pairs of corresponding words. So we have to find a mapping which would map their embeddings to be as near as possible.\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F, \\text{where} ||*||_F - \\text{Frobenius norm}$$\n",
        "\n",
        "This function is similar to the linear regression (without bias).\n",
        "\n",
        "**Task** Implement it - use `LinearRegression` from sklearn with `fit_intercept=False`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fraTOQtu1YWI"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "mapping = LinearRegression(fit_intercept=False).fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrzRk3ja1b_6"
      },
      "source": [
        "Check it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quax6HnF1aON"
      },
      "source": [
        "august = mapping.predict(uk_emb[\"\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih1GLNZt1nZX"
      },
      "source": [
        "Expected that the top contains different months, but `` is not the first.\n",
        "\n",
        "We are going to evaluate the mapping by precision@k metric with k = 1, 5, 10.\n",
        "\n",
        "**Task** Implement following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnmrLp9y2gNI"
      },
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    <implement it>\n",
        "    return precision_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1NIvhSH2olG"
      },
      "source": [
        "assert precision([(\"\", \"\")], august, topn=5) == 0.0\n",
        "assert precision([(\"\", \"\")], august, topn=9) == 1.0\n",
        "assert precision([(\"\", \"\")], august, topn=10) == 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ml_w1Tl2r7Y"
      },
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9KQHMr2tx8"
      },
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
        "\n",
        "assert precision_top1 >= 0.635\n",
        "assert precision_top5 >= 0.813"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNbDTP502urT"
      },
      "source": [
        "### Improving Mapping\n",
        "\n",
        "It can be proven that the mapping with orthogonal constraint is better:\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "You can find it using SVD:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "\n",
        "$$W^*=UV^T$$\n",
        "\n",
        "**Task** Implement the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9de8XZ_F3v53"
      },
      "source": [
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\" \n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"    \n",
        "    <calculate it>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WeCadzN382y"
      },
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6qaMb0E3-f9"
      },
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"\"], W)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nn58crh4AH0"
      },
      "source": [
        "assert precision(uk_ru_test, np.matmul(X_test, W)) >= 0.653\n",
        "assert precision(uk_ru_test, np.matmul(X_test, W), 5) >= 0.824"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqgcYk-c4DE5"
      },
      "source": [
        "### Writing the translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwi70fP6FaAN"
      },
      "source": [
        "Now we are ready to implement the translation function. It should find the nearest vector in the target (Russian) embedding space and return the source word if it is not in the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0etAHUks4JOr"
      },
      "source": [
        "with open(\"fairy_tale.txt\", \"r\") as in f:\n",
        "    uk_sentences = [line.rstrip().lower() for line in in f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK_FJGmn4N7V"
      },
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    <implement it>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47pbFyk4P6D"
      },
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"  \") == \"  \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAVWK7mE4RYU"
      },
      "source": [
        "for sentence in uk_sentences:\n",
        "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5GrChTeFqIg"
      },
      "source": [
        "# Supplementary Materials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwffxpbmFwDh"
      },
      "source": [
        "## To read\n",
        "### Basic knowledge:  \n",
        "[On word embeddings - Part 1, Sebastian Ruder](http://ruder.io/word-embeddings-1/)  \n",
        "[Deep Learning, NLP, and Representations, Christopher Olah](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)  \n",
        "\n",
        "### How to clusterize embeddings:  \n",
        "[Making Sense of Word Embeddings (2016), Pelevina et al](http://anthology.aclweb.org/W16-1620)    \n",
        "\n",
        "### How to evaluate embeddings:\n",
        "[Evaluation methods for unsupervised word embeddings (2015), T. Schnabel](http://www.aclweb.org/anthology/D15-1036)  \n",
        "[Intrinsic Evaluation of Word Vectors Fails to Predict Extrinsic Performance (2016), B. Chiu](https://www.aclweb.org/anthology/W/W16/W16-2501.pdf)  \n",
        "[Problems With Evaluation of Word Embeddings Using Word Similarity Tasks (2016), M. Faruqui](https://arxiv.org/pdf/1605.02276.pdf)  \n",
        "[Improving Reliability of Word Similarity Evaluation by Redesigning Annotation Task and Performance Measure (2016), Oded Avraham, Yoav Goldberg](https://arxiv.org/pdf/1611.03641.pdf)  \n",
        "[Evaluating Word Embeddings Using a Representative Suite of Practical Tasks (2016), N. Nayak](https://cs.stanford.edu/~angeli/papers/2016-acl-veceval.pdf)  \n",
        "\n",
        "\n",
        "## To watch\n",
        "[Word Vector Representations: word2vec, Lecture 2, cs224n](https://www.youtube.com/watch?v=ERibwqs9p38)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vacV4BIFI8l"
      },
      "source": [
        "!pip3 -qq install torch==1.1\n",
        "!pip -qq install nltk==3.2.5\n",
        "!pip -qq install gensim==3.6.0\n",
        "!pip -qq install bokeh==1.0.4\n",
        "\n",
        "!wget -O quora.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ERtxpdWOgGQ3HOigqAMHTJjmOE_tWvoF\"\n",
        "!unzip quora.zip\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIFSTdJG95SZ"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbpWIAreB6ky"
      },
      "source": [
        "# Introduction to PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M0mMOadG8aZ"
      },
      "source": [
        "PyTorch is one of the most well-known frameworks for building neural networks (which is what we're gonna do in this course).\n",
        "\n",
        "The most obvious alternative is Tensorflow, but right now (at fall of 2018) it's much less user-friendly so we'll stick to pytorch.\n",
        "\n",
        "And come on, if you learn one of them, you'll be able to learn another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsScdJ7DLZCm"
      },
      "source": [
        "## Automatic Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1bSmJbXOPbk"
      },
      "source": [
        "Let's start with one of the fundamental pytorch concepts - automatic differentiation (autograd)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY9FHLM-M4aW"
      },
      "source": [
        "### Computational Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkvCloDpNXdH"
      },
      "source": [
        "Computational graphs provide a very convenient way to represent functions and calculate their gradients.\n",
        "\n",
        "For instance,\n",
        "$$f = (x + y) \\cdot z$$\n",
        "\n",
        "Can be represented with this graph:  \n",
        "![graph](https://github.com/DanAnastasyev/DeepNLP-Course/raw/master/Week%2003/Images/Circuit.png)  \n",
        "*From [Backpropagation, Intuitions - CS231n](http://cs231n.github.io/optimization-2/)*\n",
        "\n",
        "*The forward pass* computes value of the function (green numbers). It starts from the inputs (on the left) and applies the sequence of functions.\n",
        "\n",
        "*The backward pass* (or *back propagation*) is designed to compute gradients of the function. That is $\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z}$ in our case. It starts from the output and applies *chain rule* to compute them.\n",
        "\n",
        "For instance, for $f = q \\cdot z$, we have $\\frac{\\partial f}{\\partial q} = z$ and $\\frac{\\partial f}{\\partial z} = q$.  \n",
        "For $q = x + y$, we have $\\frac{\\partial q}{\\partial x} = \\frac{\\partial q}{\\partial y} = 1$.  \n",
        "Finally, we can apply the chain rule: $\\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial q} \\frac{\\partial q}{\\partial x} = z$.\n",
        "\n",
        "*If you had problems with understanding the stuff above (and even if didn't), check this great tutorial: [Backpropagation, Intuitions - CS231n](http://cs231n.github.io/optimization-2/).*\n",
        "\n",
        "Well, such calculations in pytorch are fairly simple. You just have to describe your function as a sequence of operations, like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4ASRktLdO4"
      },
      "source": [
        "x = torch.tensor(-2., requires_grad=True)\n",
        "y = torch.tensor(5., requires_grad=True)\n",
        "z = torch.tensor(-4., requires_grad=True)\n",
        "\n",
        "q = x + y\n",
        "f = q * z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-78COM99N8YL"
      },
      "source": [
        "Call it with some arguments and then ask it like, \"Hey, calc your grads, please\". And the magic happens:\n",
        "\n",
        "![graph](https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/dynamic_graph.gif)  \n",
        "*From [github.com/pytorch/pytorch](https://github.com/pytorch/pytorch)*\n",
        "\n",
        "Pytorch builds graph and performs backward pass - all by itself.\n",
        "\n",
        "If you already know tensorflow, you'll see the main difference: graph is built dynamically, it hasn't be compiled and stuff. \n",
        "\n",
        "Basically, it means that you can debug your code much more easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FOlPMIQMfbq"
      },
      "source": [
        "f.backward()\n",
        "\n",
        "print('df/dz =', z.grad)\n",
        "print('df/dx =', x.grad)\n",
        "print('df/dy =', y.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JotDf1naGU-R"
      },
      "source": [
        "The call of the `backward()` method calculates gradients for all tensors in graph (except the subgraphs where `requires_grad == False`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSiB1CGyJMzt"
      },
      "source": [
        "*Read about autograd in pytorch in depth here: [Autograd mechanics](https://pytorch.org/docs/stable/notes/autograd.html).*\n",
        "\n",
        "Well, the nicest thing about pytorch is that you can use it like you used numpy. You use `ndarray` all the time, right.\n",
        "\n",
        "There is an analog for it - `tensor`. We just created few of them actually.\n",
        "\n",
        "It stores data, like `ndarray`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY2CcCw2Gmgq"
      },
      "source": [
        "x.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYxD8N_9GpJl"
      },
      "source": [
        "And gradient (unlike `ndarray`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYCD5P24GufX"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwLx4szvGwMb"
      },
      "source": [
        "Add function used to compute the gradient:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTfGdUF_GzV8"
      },
      "source": [
        "q.grad_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgK1Esa6HHAB"
      },
      "source": [
        "And lots of meta-info:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nazaer0AG4pL"
      },
      "source": [
        "x.type(), x.shape, x.device, x.layout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Be6fwAky0pr"
      },
      "source": [
        "Check this tutorial to learn more about tensors: [Deep Learning with PyTorch: A 60 Minute Blitz > What is PyTorch?](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
        "\n",
        "Sometimes we don't want to compute the gradients. To handle this cases (we'll discuss particular examples very soon), you can use context managers ([Locally disabling gradient computation](https://pytorch.org/docs/stable/autograd.html#locally-disabling-gradient-computation)):\n",
        "```python\n",
        "torch.autograd.no_grad()\n",
        "torch.autograd.enable_grad()\n",
        "torch.autograd.set_grad_enabled(mode)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQEJeqfnJPpA"
      },
      "source": [
        "with torch.autograd.no_grad():\n",
        "    x = torch.tensor(-2., requires_grad=True)\n",
        "    y = torch.tensor(5., requires_grad=True)\n",
        "    q = x + y\n",
        "\n",
        "z = torch.tensor(-4., requires_grad=True)\n",
        "f = q * z\n",
        "\n",
        "f.backward()\n",
        "\n",
        "print('df/dz =', z.grad)\n",
        "print('df/dx =', x.grad)\n",
        "print('df/dy =', y.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvLFlc4iQOQv"
      },
      "source": [
        "Well, the question is why on earth you would want it to use :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlhLBWwHG3Xe"
      },
      "source": [
        "### Warm-up Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaqtIIvJOEut"
      },
      "source": [
        "To understand it, let's write a simple linear regression implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDZpEHF8AKH2"
      },
      "source": [
        "w_orig, b_orig = 2.6, -0.4\n",
        "\n",
        "X = np.random.rand(100) * 10. - 5.\n",
        "y_orig = w_orig * X + b_orig\n",
        "\n",
        "y = y_orig + np.random.randn(100)\n",
        "\n",
        "plt.plot(X, y, '.')\n",
        "plt.plot(X, y_orig)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2K5MVtiSGuC"
      },
      "source": [
        "There are two parameters $w$ and $b$. We want them to be as near to $w_{orig}, b_{orig}$ as possible.\n",
        "\n",
        "What are we going to optimize? Let's optimize MSE loss:\n",
        "$$J(w, b) = \\frac{1}{N} \\sum_{i=1}^N || \\hat y_i - y_i(w, b)||^2 =\\frac{1}{N} \\sum_{i=1}^N || \\hat y_i - (w \\cdot x_i + b)||^2. $$\n",
        "\n",
        "We can use *gradient descent* algorithm to optimize it (not even stohastic right now):\n",
        "$$w_{t+1} := w_t - \\alpha \\cdot \\frac{\\partial J}{\\partial w}(w_t, b_t)$$\n",
        "$$b_{t+1} := w_t - \\alpha \\cdot \\frac{\\partial J}{\\partial b}(w_t, b_t)$$\n",
        "\n",
        "*You see, it would be nice to use backpropagation here.*\n",
        "\n",
        "**Task** Implement the optimization using pure numpy.\n",
        "\n",
        "You'll need:\n",
        "1. Perform the forward pass: $y(w, b) = w \\cdot x + b$;\n",
        "2. Find the gradients $\\frac{\\partial J}{\\partial w}, \\frac{\\partial J}{\\partial b}$ using backward pass;\n",
        "3. Move $w, b$ in the anti-gradients direction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKbqTNVXFB3A"
      },
      "source": [
        "def display_progress(epoch, loss, w, b, X, y, y_pred):\n",
        "    clear_output(True)\n",
        "    print('Epoch = {}, Loss = {}, w = {}, b = {}'.format(epoch, loss, w, b))\n",
        "    plt.plot(X, y, '.')\n",
        "    plt.plot(X, y_pred)\n",
        "    plt.show()\n",
        "    time.sleep(1)\n",
        "\n",
        "\n",
        "w = np.random.randn()\n",
        "b = np.random.randn()\n",
        "\n",
        "alpha = 0.01\n",
        "\n",
        "for i in range(100):\n",
        "    <calculate model's output>\n",
        "    \n",
        "    <calculate loss>\n",
        "    \n",
        "    <calculate gradients>\n",
        "    \n",
        "    <update w and b>\n",
        "    \n",
        "    if (i + 1) % 5 == 0:\n",
        "        display_progress(i + 1, loss, w, b, X, y, y_pred)\n",
        "        \n",
        "assert np.abs(w - w_orig) < 0.1, 'Something went wrong :('"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8WgWrF4C2WK"
      },
      "source": [
        "It's much simpler to implement the same thing using pytorch.\n",
        "\n",
        "The forward pass will look almost the same. And we've already learnt how to perform the backward pass! Just call `loss.backward()`.\n",
        "\n",
        "But there are a number of caveats you have to know about. \n",
        "\n",
        "First of all, one doen't simply update `w` and `b`. Try this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx4DoGeBMJd4"
      },
      "source": [
        "w = torch.randn(1, requires_grad=True)\n",
        "\n",
        "w -= 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OjoUh-SMPBt"
      },
      "source": [
        "It should fail with a message like:  \n",
        "`RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.`\n",
        "\n",
        "The issue is in the support of in-place operations in autograd: [In place operations with autograd](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd).\n",
        "\n",
        "But actually we are not going to perform an operation that requires gradients. We're just updating the value of the note.\n",
        "\n",
        "To fight this problem, we can either use `no_grad` context or update the underline data used by the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zegkKd-cMOMj"
      },
      "source": [
        "w.data -= 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVlaIdvHNXR_"
      },
      "source": [
        "Another thing you should be aware of is that the gradients are accumulating by default. So you have to update them yourself between `loss.backward()` calls:\n",
        "```python\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "```\n",
        "\n",
        "**Task** Implement the linear regression on pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRqxypuEU2ig"
      },
      "source": [
        "X = torch.as_tensor(X).float()\n",
        "y = torch.as_tensor(y).float()\n",
        "\n",
        "w = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "for i in range(100):\n",
        "    <copy forward pass and add backward pass + parameters updates>\n",
        "    \n",
        "    if (i + 1) % 5 == 0:\n",
        "        display_progress(i + 1, loss, w.item(), b.item(), \n",
        "                         X.data.numpy(), y.data.numpy(), y_pred.data.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaKTKN_fOvo-"
      },
      "source": [
        "Much simpler, isn't it? :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZNq6ujzPtvd"
      },
      "source": [
        "## Word Embeddings (via High-Level PyTorch API)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITLgcVz66AfV"
      },
      "source": [
        "Let's move now to more high-level API, where all the good neural network parts are implemented. Quite comprehensive description of it is given in this tutorial: [What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
        "\n",
        "Last time we used gensim to train word2vec model. Now we're ready to implement our own model.\n",
        "\n",
        "Well, almost ready. We still haven't discussed what word2vec is.\n",
        "\n",
        "The key idea is simple: you can understand the meaning of the word by his neighbours (the words that appear frequently in its context):  \n",
        "![contexts](https://image.ibb.co/mnQ2uz/2018_09_17_21_07_08.png)\n",
        "*From [cs224n, Lecture 2](http://web.stanford.edu/class/cs224n/lectures/lecture2.pdf)*\n",
        "\n",
        "The first idea is just to use counts of the words in context as a meaningful word vector.\n",
        "\n",
        "For instance, for such simple corpus:\n",
        "\n",
        "```\n",
        "The red fox jumped\n",
        "The brown fox jumped\n",
        "```\n",
        "\n",
        "we'll have following count vectors:\n",
        "```\n",
        "        the fox jumped red brown\n",
        "red   = (1   1    1     0    0)\n",
        "brown = (1   1    1     0    0)\n",
        "```\n",
        "\n",
        "You see, `red` and `brown` have similar vector! The problem is almost solved. But we have to obtain much smaller embedding vectors.\n",
        "\n",
        "And here is what word2vec algorithms do. They build embedding vectors based on the neighbours of the word in corpus.\n",
        "\n",
        "A nice introduction is given in this post: [king - man + woman is queen; but why?](http://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html)\n",
        "\n",
        "Let's do some preparation work before moving to the interesting stuff.\n",
        "\n",
        "**Task** Tokenize and lower-case texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKKb9Ya8hzIb"
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "quora_data = pd.read_csv('train.csv')\n",
        "\n",
        "quora_data.question1 = quora_data.question1.replace(np.nan, '', regex=True)\n",
        "quora_data.question2 = quora_data.question2.replace(np.nan, '', regex=True)\n",
        "\n",
        "texts = list(pd.concat([quora_data.question1, quora_data.question2]).unique())\n",
        "\n",
        "tokenized_texts = [<do it there>]\n",
        "\n",
        "assert len(tokenized_texts) == len(texts)\n",
        "assert isinstance(tokenized_texts[0], list)\n",
        "assert isinstance(tokenized_texts[0][0], str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYoj91iDDDfT"
      },
      "source": [
        "Collect the indices of the most frequent words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PL471pGjuVN"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "MIN_COUNT = 5\n",
        "\n",
        "words_counter = Counter(token for tokens in tokenized_texts for token in tokens)\n",
        "word2index = {\n",
        "    '<unk>': 0\n",
        "}\n",
        "\n",
        "for word, count in words_counter.most_common():\n",
        "    if count < MIN_COUNT:\n",
        "        break\n",
        "        \n",
        "    word2index[word] = len(word2index)\n",
        "    \n",
        "index2word = [word for word, _ in sorted(word2index.items(), key=lambda x: x[1])]\n",
        "    \n",
        "print('Vocabulary size:', len(word2index))\n",
        "print('Tokens count:', sum(len(tokens) for tokens in tokenized_texts))\n",
        "print('Unknown tokens appeared:', sum(1 for tokens in tokenized_texts for token in tokens if token not in word2index))\n",
        "print('Most freq words:', index2word[1:21])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF5mYpCsE9Uh"
      },
      "source": [
        "### Skip-Gram Word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om1IG5XEMGRa"
      },
      "source": [
        "Word2vec is actually a set of models used to build word embeddings.\n",
        "\n",
        "We are going to start with the *skip-gram model*.\n",
        "\n",
        "It's a very simple neural network with just two layers. It aims to build word vectors that encode information about the co-occurring words:  \n",
        "![](https://i.ibb.co/nL0LLD2/Word2vec-Example.jpg)  \n",
        "*From cs224n, Lecture 2*\n",
        "\n",
        "More precisely, it models the probabilities $\\{P(w_{c+j}|w_c):  j = c-k, ..., c+k, j \\neq c\\}$, where $k$ is the context window size, $c$ is index of the central word (which embedding we are trying to optimize).\n",
        "\n",
        "The learnable parameters of the model are following: matrix $U$ (embeddings' matrix that is used in all downstream tasks. In gensim it's called `syn0`) and matrix $V$ - output layer of the model (in gensim it's called `syn1`).\n",
        "\n",
        "Two vectors correspond to each word: a row in $U$ and a column in $V$. That is $U \\in \\mathbb{R}^{|V|, d}$ and $V \\in \\mathbb{R}^{d, |V|}$, where $d$ is embedding size and $|V|$ is the vocabulary size.\n",
        "\n",
        "As a result, the neural network looks this way:  \n",
        "![skip-gram](https://i.ibb.co/F54XzDC/SkipGram.png)\n",
        "\n",
        "What's going on and how it is connected to probability and word context?\n",
        "\n",
        "Well, the word is mapped to its embedding $u_c$. Then this embedding is multiplied to matrix $V$. \n",
        "\n",
        "As a result, we obtain the set of scores $\\{v_j^T u_c : j \\in {0, \\ldots, |V|}\\}$. Each corresponds to the similarity between the word $w_j$ vector and our word vector. It's very similar to the cosine similarity we calculated in the previous lesson, but without normalization.\n",
        "\n",
        "This similarities show how likely $w_j$ can be in context of word $w_c$. That means, that they can be converted to probability using the softmax function:\n",
        "$$P(w_j | w_c) = \\frac{\\exp(v_{j}^T u_c)}{\\sum_{i=1}^{|V|} \\exp(v_i^T u_c)}.$$\n",
        "\n",
        "So for each word we calculate such probability distribution over our vocabulary. It's shown in using blue bars in the picture above. More likely word - bluer is the corresponding cell.\n",
        "\n",
        "The model learns to distribute the probabilities between the co-occuring words for the given one. We'll use cross-entropy loss for it:\n",
        "$$-\\sum_{-k \\leq j \\leq k, j \\neq 0} \\log \\frac{\\exp(v_{c+j}^T u_c)}{\\sum_{i=1}^{|V|} \\exp(v_i^T u_c)} \\to \\min_{U, V}.$$\n",
        "\n",
        "For instance, for the sample from the picture model will be penalized if it outputs a low probability of word `over`.\n",
        "\n",
        "Please, notice that we calculate the similarity between vectors from different vector spaces. $u_c$ is the vector from the input embeddings and $v_j$ is the vector from the output embeddings. A high similarity between them means that they co-occur frequently, not that they are similar in the syntactic role or their semantics.\n",
        "\n",
        "On the other hand, the similarity between $u_k$ and $u_m$ means that their output distributions are similar. And that means exactly that the similarity of the count vectors we discussed before and also most probably means their syntactic or semantic similarity.\n",
        "\n",
        "Check this demo to understand what's going on in more depth: [https://ronxin.github.io/wevi/](https://ronxin.github.io/wevi/).\n",
        "\n",
        "Let's implement it now!\n",
        "\n",
        "#### Batches Generations\n",
        "\n",
        "First of all, we need to collect all the contexts from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocrsXgaynYPG"
      },
      "source": [
        "def build_contexts(tokenized_texts, window_size):\n",
        "    contexts = []\n",
        "    for tokens in tokenized_texts:\n",
        "        for i in range(len(tokens)):\n",
        "            central_word = tokens[i]\n",
        "            context = [tokens[i + delta] for delta in range(-window_size, window_size + 1) \n",
        "                       if delta != 0 and i + delta >= 0 and i + delta < len(tokens)]\n",
        "\n",
        "            contexts.append((central_word, context))\n",
        "            \n",
        "    return contexts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQBa6yQ9BXjp"
      },
      "source": [
        "contexts = build_contexts(tokenized_texts, window_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o_ePiZ7wfpT"
      },
      "source": [
        "Check, what you got:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQNK-9SBdb9"
      },
      "source": [
        "contexts[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbQKln_6yC4l"
      },
      "source": [
        "Let's convert words to indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOPRlKlLvUBA"
      },
      "source": [
        "contexts = [(word2index.get(central_word, 0), [word2index.get(word, 0) for word in context]) \n",
        "            for central_word, context in contexts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYmrAi9gyIe-"
      },
      "source": [
        "Neural networks are optimized using stochastic gradient descent methods. Which means, we need a batch generator - a function that generates samples to optimize neural network with.\n",
        "\n",
        "A simple batch generator looks this way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC9SifFU5iQP"
      },
      "source": [
        "import random\n",
        "\n",
        "def make_skip_gram_batches_iter(contexts, window_size, num_skips, batch_size):\n",
        "    assert batch_size % num_skips == 0\n",
        "    assert num_skips <= 2 * window_size\n",
        "    \n",
        "    central_words = [word for word, context in contexts if len(context) == 2 * window_size and word != 0]\n",
        "    contexts = [context for word, context in contexts if len(context) == 2 * window_size and word != 0]\n",
        "    \n",
        "    batch_size = int(batch_size / num_skips)\n",
        "    batches_count = int(math.ceil(len(contexts) / batch_size))\n",
        "    \n",
        "    print('Initializing batches generator with {} batches per epoch'.format(batches_count))\n",
        "    \n",
        "    while True:\n",
        "        indices = np.arange(len(contexts))\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(batches_count):\n",
        "            batch_begin, batch_end = i * batch_size, min((i + 1) * batch_size, len(contexts))\n",
        "            batch_indices = indices[batch_begin: batch_end]\n",
        "\n",
        "            batch_data, batch_labels = [], []\n",
        "\n",
        "            for data_ind in batch_indices:\n",
        "                central_word, context = central_words[data_ind], contexts[data_ind]\n",
        "                \n",
        "                words_to_use = random.sample(context, num_skips)\n",
        "                batch_data.extend([central_word] * num_skips)\n",
        "                batch_labels.extend(words_to_use)\n",
        "            \n",
        "            yield {\n",
        "                'tokens': torch.cuda.LongTensor(batch_data), \n",
        "                'labels': torch.cuda.LongTensor(batch_labels)\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmRGZ-vG5iQR"
      },
      "source": [
        "Check it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Yeowx15iQS"
      },
      "source": [
        "batch = next(make_skip_gram_batches_iter(contexts, window_size=2, num_skips=2, batch_size=32))\n",
        "\n",
        "batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DXjZS3JyQZh"
      },
      "source": [
        "#### nn.Sequential\n",
        "\n",
        "The simplest way to implement a model on pytorch is to use `nn.Sequential`. Just define the order of layers and it will apply them sequentially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRw9Z4G__46O"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Embedding(len(word2index), 32),\n",
        "    nn.Linear(32, len(word2index))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysn0DDpLyj1S"
      },
      "source": [
        "Yep, we've just defined our skip-gram model! \n",
        "\n",
        "The construction above says that we need a `nn.Embedding` layer (a layer that maps index to a vector. In our case it would be an index from the `range(len(word2index))` and a 32-dimensional vector) following by a `nn.Linear` layer (just a dot-product of an input vector to the learnable matrix with addition of a learnable bias).\n",
        "\n",
        "There is another pytorch's feature we haven't discussed yet. It's computations on GPU. Neural networks are usually trained on GPUs because it's much faster.\n",
        "\n",
        "It's extremely easy to ask pytorch to perform calculations on the GPU. Just call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfmaUi3Uy9YT"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3c3UEa2zHhk"
      },
      "source": [
        "or"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHxAg5ZWzEKT"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prP1avp-5DjZ"
      },
      "source": [
        "We'll apply it to the data in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsa-P9VS49RD"
      },
      "source": [
        "tokens, labels = batch['tokens'], batch['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtLMvOO2z3c8"
      },
      "source": [
        "Now, to perform the forward pass just call the model with its input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9wTpewTz3Dk"
      },
      "source": [
        "logits = model(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWJmDy_uzJgD"
      },
      "source": [
        "We can calculate the loss now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7rlD62_ykYl"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss = criterion(logits, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAwx-pck0RxX"
      },
      "source": [
        "And, of course, perform the backward pass:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWt6gL0_0Npp"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJkDOl6szRLm"
      },
      "source": [
        "Finally, we have to update the parameters. We can do it as before (like, `w.data -= alpha * w.grad`). But pytorch contains predefined optimizers that can do the same things (and more complicated stuff).\n",
        "\n",
        "We are going to use Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-b5CIARzQ6m"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju5lO0Xi0hsV"
      },
      "source": [
        "To update the weights just call `optimizer.step()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9QK7nHu0Zw8"
      },
      "source": [
        "print(model[1].weight)\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "print(model[1].weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnxyk1ew0pSk"
      },
      "source": [
        "And finally, don't forget to zero grads!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMsuvEP90svi"
      },
      "source": [
        "optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXSzfnLf3hDa"
      },
      "source": [
        "You can ask optimizer to do it for you, you see."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PibTw33Azg7q"
      },
      "source": [
        "#### Train Cycle\n",
        "\n",
        "We are ready to implement the training cycle - just like we did for our linear regression.\n",
        "\n",
        "**Task** Implement the cycle. Train the model for a few epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewGMgYTXANzz"
      },
      "source": [
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for step, (batch, labels) in enumerate(make_skip_gram_batches_iter(contexts, window_size=2, num_skips=4, batch_size=128)):\n",
        "    <1. convert data to tensors>\n",
        "    \n",
        "    <2. make forward pass>\n",
        "\n",
        "    <3. make backward pass>\n",
        "\n",
        "    <4. apply optimizer>\n",
        "    \n",
        "    <5. zero grads>\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
        "                                                                    time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqq9kee41L4P"
      },
      "source": [
        "#### Analysis\n",
        "\n",
        "To get the embedding matrix, cast the following magic:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWsYkNn-Hnl_"
      },
      "source": [
        "embeddings = model[0].weight.data.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fvE2za248_A"
      },
      "source": [
        "That is, we get the weights from the first layer of the model, move them from gpu to cpu and convert to numpy array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZtxY2D01RB6"
      },
      "source": [
        "Let's check how adequate are similarities that the model learnt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhDwuhDSHEDm"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def most_similar(embeddings, index2word, word2index, word):\n",
        "    word_emb = embeddings[word2index[word]]\n",
        "    \n",
        "    similarities = cosine_similarity([word_emb], embeddings)[0]\n",
        "    top10 = np.argsort(similarities)[-10:]\n",
        "    \n",
        "    return [index2word[index] for index in reversed(top10)]\n",
        "\n",
        "most_similar(embeddings, index2word, word2index, 'warm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VS1x-mO1WKS"
      },
      "source": [
        "And visualizations!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuXv2HxsAecb"
      },
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig\n",
        "\n",
        "\n",
        "def get_tsne_projection(word_vectors):\n",
        "    tsne = TSNE(n_components=2, verbose=100)\n",
        "    return scale(tsne.fit_transform(word_vectors))\n",
        "    \n",
        "    \n",
        "def visualize_embeddings(embeddings, index2word, word_count):\n",
        "    word_vectors = embeddings[1: word_count + 1]\n",
        "    words = index2word[1: word_count + 1]\n",
        "    \n",
        "    word_tsne = get_tsne_projection(word_vectors)\n",
        "    draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)\n",
        "    \n",
        "    \n",
        "visualize_embeddings(embeddings, index2word, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGfhLR6x8D3r"
      },
      "source": [
        "### Continuous Bag of Words (CBoW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UuVr2IsaYhX"
      },
      "source": [
        "Here is an alternative word2vec model:\n",
        "\n",
        "![](https://i.ibb.co/StXTMFH/CBOW.png)\n",
        "\n",
        "Now we have to predict the word by its context. The context is represented as a sum of context vectors.\n",
        "\n",
        "**Task** Implement the batch generator. It should output a context matrix `(samples_count, 2 * window_size)` which contains the context word indices and a target matrix `(samples_count)` with the central word indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNaP0uaU7T2-"
      },
      "source": [
        "def make_cbow_batches_iter(contexts, window_size, batch_size):\n",
        "    data = np.array([context for word, context in contexts if len(context) == 2 * window_size and word != 0])\n",
        "    labels = np.array([word for word, context in contexts if len(context) == 2 * window_size and word != 0])\n",
        "        \n",
        "    batches_count = int(math.ceil(len(data) / batch_size))\n",
        "    \n",
        "    print('Initializing batches generator with {} batches per epoch'.format(batches_count))\n",
        "    \n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(batches_count):\n",
        "            <implement the generator>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBF7xiik7ZaN"
      },
      "source": [
        "Check it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IVrQl8S4L9j"
      },
      "source": [
        "window_size = 2\n",
        "batch_size = 32\n",
        "\n",
        "batch = next(make_cbow_batches_iter(contexts, window_size=window_size, batch_size=batch_size))\n",
        "\n",
        "assert isinstance(batch, dict)\n",
        "assert 'labels' in batch and 'tokens' in batch\n",
        "\n",
        "assert isinstance(batch['tokens'], torch.cuda.LongTensor)\n",
        "assert isinstance(batch['labels'], torch.cuda.LongTensor)\n",
        "\n",
        "assert batch['tokens'].shape == (batch_size, 2 * window_size)\n",
        "assert batch['labels'].shape == (batch_size,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbKbZ_4E7T3U"
      },
      "source": [
        "The alternative way to define a model is to inherit it from `nn.Module`. It's a more flexible approach than defining a `nn.Sequential` model so we are going to use it mostly\n",
        "\n",
        "```python\n",
        "class MyNetModel(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MyNetModel, self).__init__()\n",
        "        <initialize layers>\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        <apply layers>\n",
        "        return final_output\n",
        "```\n",
        "\n",
        "You have to create all the learnable parameters (usually - layers) of the model in the `__init__` method and you have to apply them in the `forward` method.\n",
        "\n",
        "**Task** Build the `CBoWModel`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkawxwe77T3V"
      },
      "source": [
        "class CBoWModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self._out_layer = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <apply the layers>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHhTDxya7a3S"
      },
      "source": [
        "Check it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh_mNh__6lG2"
      },
      "source": [
        "model = CBoWModel(vocab_size=len(word2index), embedding_dim=32).cuda()\n",
        "\n",
        "outputs = model(batch['tokens'])\n",
        "\n",
        "assert isinstance(outputs, torch.cuda.FloatTensor)\n",
        "assert outputs.shape == (batch_size, len(word2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmn56yki7T3a"
      },
      "source": [
        "**Task** Train the model in the same way as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzKLP9bs7T3b"
      },
      "source": [
        "model = CBoWModel(vocab_size=len(word2index), embedding_dim=32).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for step, batch in enumerate(make_cbow_batches_iter(contexts, window_size=2, batch_size=128)):\n",
        "    <copy-paste the learning cycle>\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
        "                                                                    time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQW4PBdF96xC"
      },
      "source": [
        "Let's visualize what we got."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTEWcyYmvips"
      },
      "source": [
        "visualize_embeddings(model.embeddings.weight.data.cpu().numpy(), index2word, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CON4VOyG3iET"
      },
      "source": [
        "### Negative Sampling\n",
        "\n",
        "What is the most computationally hard part of the model optimization? It's computation of softmax function over the vocabulary.\n",
        "\n",
        "To improve the model's performance *negative sampling* can be used.\n",
        "\n",
        "The idea is fairly obvious: let's predict the probability that the word $w$ can be in the context $c$: $P(D=1|w,c)$.\n",
        "\n",
        "The probability (again!) would be a function of the similarity between vectors: \n",
        "$$P(D=1|w, c) = \\sigma(v_w^T u_c) = \\frac 1 {1 + \\exp(-v^T_w u_c)}.$$\n",
        "\n",
        "The sigmoid function just maps the similarity to [0, 1] range.\n",
        "\n",
        "Well, we have positive samples (word-context pairs from the corpus), but we need some negative samples too to train our model. And we can generate them!  \n",
        "![Negative Sampling](https://i.ibb.co/D7rTdbr/Negative-Sampling.png)\n",
        "\n",
        "Just sample random word instead of the correct one and hope that they don't fit the context too well.\n",
        "\n",
        "The loss function (in CBoW setup) will be following:\n",
        "$$-\\log \\sigma(v_c^T u_c) - \\sum_{k=1}^K \\log \\sigma(-\\tilde v_k^T u_c),$$\n",
        "where $v_c$ - central word vector, $u_c$ - context vector (sum of vectors from the context), $\\tilde v_1, \\ldots, \\tilde v_K$ - vectors of the negative samples.\n",
        "\n",
        "Compare it with ordinary CBoW:\n",
        "$$-v_c^T u_c + \\log \\sum_{i=1}^{|V|} \\exp(v_i^T u_c).$$\n",
        "\n",
        "You see, it's quite similar, but the sum is over a much smaller number of samples.\n",
        "\n",
        "The sampling is performed from $U^{3/4}$, where $U$ - unigram distribution (word frequencies).\n",
        "\n",
        "We've already calculated the word counts (they were obtained when we called `Counter(words)`). \n",
        "\n",
        "Just convert them to frequencies and raise them to the power of $\\frac 3 4$. Why exactly $\\frac 3 4$? It's just a good constant, but the intuition is following:\n",
        "\n",
        "$$P(\\text{is}) = 0.9, \\ P(\\text{is})^{3/4} = 0.92$$\n",
        "$$P(\\text{Constitution}) = 0.09, \\ P(\\text{Constitution})^{3/4} = 0.16$$\n",
        "$$P(\\text{bombastic}) = 0.01, \\ P(\\text{bombastic})^{3/4} = 0.032$$\n",
        "\n",
        "The probability of high-frequent words stayed the same (approximately), while low-frequent words now are more likely.\n",
        "\n",
        "Nice description of this algorithm can be found in [cs224n lecture notes](https://github.com/maxim5/cs224n-winter-2017/blob/master/lecture_notes/cs224n-2017-notes1.pdf).\n",
        "\n",
        "**Task** Implement Negative Sampling.\n",
        "\n",
        "Define distribution first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcX4vRBLlXy6"
      },
      "source": [
        "words_sum_count = sum(words_counter.values())\n",
        "word_distribution = np.array([(words_counter[word] / words_sum_count) ** (3 / 4) for word in index2word])\n",
        "word_distribution /= word_distribution.sum()\n",
        "\n",
        "indices = np.arange(len(word_distribution))\n",
        "\n",
        "np.random.choice(indices, p=word_distribution, size=(32, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2pzsue16Lu"
      },
      "source": [
        "class NegativeSamplingModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self._out_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, inputs, targets, num_samples):\n",
        "        '''\n",
        "        inputs: (batch_size, context_size)\n",
        "        targets: (batch_size)\n",
        "        num_samples: int\n",
        "        Returns loss calculated like in the formula above\n",
        "        '''\n",
        "        \n",
        "        <calc u_c (using self._embedding) & v_c (using self._out_layer)>\n",
        "        \n",
        "        <obtain negative sample indices with shape (inputs.shape[0], num_samples) using np.random.choice>\n",
        "        \n",
        "        <calculate v_tilde - embeddings of the negative samples (using self._out_layer)>\n",
        "        \n",
        "        <calculate logsigmoid outputs (use F.logsigmoid)>\n",
        "\n",
        "        <return mean loss>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265oljMhKdBp"
      },
      "source": [
        "Train and visualize the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wz2iRanqzlq"
      },
      "source": [
        "model = NegativeSamplingModel(vocab_size=len(word2index), embedding_dim=32).cuda()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)  \n",
        "\n",
        "negative_samples = 20\n",
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for step, batch in enumerate(make_cbow_batches_iter(contexts, window_size=2, batch_size=128)):\n",
        "    <update the learning cycle accordingly>\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
        "                                                                    time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFik_6djvg3F"
      },
      "source": [
        "visualize_embeddings(model.embeddings.weight.data.cpu().numpy(), index2word, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4G2X-TTpzwz"
      },
      "source": [
        "### Structured Word2Vec\n",
        "\n",
        "In the paper [Two/Too Simple Adaptations of Word2Vec for Syntax Problems (2015), Ling, Wang, et al.](https://www.aclweb.org/anthology/N/N15/N15-1142.pdf) \n",
        "two ways of improvement of the embeddings are discussed: *Structured Skip-gram Model* and *Continuous Window Model*:   \n",
        "![](https://i.ibb.co/56w8MC8/Structured-Word2vec.png)  \n",
        "*From Two/Too Simple Adaptations of Word2Vec for Syntax Problems*\n",
        "\n",
        "In contract to the classic word2vec, each context word has its own embedding matrix. The idea is that the words order is meaningful and by learning the order embeddings learn syntax better.\n",
        "\n",
        "The disadvantage of such approach is that you have to learn much more parameters in the model.\n",
        "\n",
        "**Task** Read the paper and implement at least one of the described methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEazfh1s9eki"
      },
      "source": [
        "class CWindowModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, window_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        <create layers>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <apply 'em>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uF6iF6A9uGQ"
      },
      "source": [
        "model = CWindowModel(vocab_size=len(word2index), embedding_dim=32, window_size=2).cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)  \n",
        "\n",
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for step, batch in enumerate(make_cbow_batches_iter(contexts, window_size=2, batch_size=128)):\n",
        "    <copy-paste the cycle yet again>\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
        "                                                                    time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqDmuu7m_PB5"
      },
      "source": [
        "# Supplementary Materials\n",
        "\n",
        "## To read\n",
        "### Blogs\n",
        "[On word embeddings - Part 1, Sebastian Ruder](http://ruder.io/word-embeddings-1/)  \n",
        "[On word embeddings - Part 2: Approximating the Softmax, Sebastian Ruder](http://ruder.io/word-embeddings-softmax/index.html)  \n",
        "[Word2Vec Tutorial - The Skip-Gram Model, Chris McCormick](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)  \n",
        "[Word2Vec Tutorial Part 2 - Negative Sampling, Chris McCormick](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/) \n",
        "\n",
        "### Papers\n",
        "[Word2vec Parameter Learning Explained (2014), Xin Rong](https://arxiv.org/abs/1411.2738)  \n",
        "[Neural word embedding as implicit matrix factorization (2014), Levy, Omer, and Yoav Goldberg](http://u.cs.biu.ac.il/~nlp/wp-content/uploads/Neural-Word-Embeddings-as-Implicit-Matrix-Factorization-NIPS-2014.pdf)  \n",
        "\n",
        "### Enhancing Embeddings\n",
        "[Two/Too Simple Adaptations of Word2Vec for Syntax Problems (2015), Ling, Wang, et al.](https://www.aclweb.org/anthology/N/N15/N15-1142.pdf)  \n",
        "[Not All Neural Embeddings are Born Equal (2014)](https://arxiv.org/pdf/1410.0718.pdf)  \n",
        "[Retrofitting Word Vectors to Semantic Lexicons (2014), M. Faruqui, et al.](https://arxiv.org/pdf/1411.4166.pdf)  \n",
        "[All-but-the-top: Simple and Effective Postprocessing for Word Representations (2017), Mu, et al.](https://arxiv.org/pdf/1702.01417.pdf)  \n",
        "\n",
        "### Sentence Embeddings\n",
        "[Skip-Thought Vectors (2015), Kiros, et al.](https://arxiv.org/pdf/1506.06726)  \n",
        "\n",
        "### Backpropagation\n",
        "[Backpropagation, Intuitions, cs231n + next parts in the Module 1](http://cs231n.github.io/optimization-2/)   \n",
        "[Calculus on Computational Graphs: Backpropagation, Christopher Olah](http://colah.github.io/posts/2015-08-Backprop/)\n",
        "\n",
        "## To watch\n",
        "[cs224n \"Lecture 2 - Word Vector Representations: word2vec\"](https://www.youtube.com/watch?v=ERibwqs9p38&index=2&list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja&t=0s)  \n",
        "[cs224n \"Lecture 5 - Backpropagation\"](https://www.youtube.com/watch?v=isPiE-DBagM&index=5&list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja&t=0s)   \n"
      ]
    }
  ]
}